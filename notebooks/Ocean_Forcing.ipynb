{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967da8d-decc-4043-8e5b-eda099aa8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Iterable, Hashable, Callable, List\n",
    "from functools import partial\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pyproj import Transformer\n",
    "from datetime import datetime, timedelta\n",
    "import pylab as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b5bf4-7cac-4d5d-8759-c99c1f6b7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nc(\n",
    "    ds: xr.Dataset,\n",
    "    regexp: str = \"id_(.+?)_\",\n",
    "    dim: str = \"exp_id\",\n",
    "    drop_vars: Union[str, Iterable[Hashable], Callable[[xr.Dataset], Union[str, Iterable[Hashable]]]] = [\"nv4\"],\n",
    "    drop_dims: List[str] = [\"nv4\"],\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Add experiment 'exp_id' to the dataset and drop specified variables and dimensions.\n",
    "\n",
    "    This function adds an experiment id ('exp_id') to the dataset, extracted from the source encoding\n",
    "    using the provided regular expression. It then drops the specified variables and dimensions from the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xr.Dataset\n",
    "        The dataset to be preprocessed.\n",
    "    regexp : str, optional\n",
    "        The regular expression used to extract the experiment id from the source encoding, by default \"id_(.+?)_\".\n",
    "    dim : str, optional\n",
    "        The name of the dimension to be added to the dataset, by default \"exp_id\".\n",
    "    drop_vars : Union[List[str], None], optional\n",
    "        The variables to be dropped from the dataset, by default None.\n",
    "    drop_dims : List[str], optional\n",
    "        The dimensions to be dropped from the dataset, by default [\"nv4\"].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "        The preprocessed dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    m_id_re = re.search(regexp, ds.encoding[\"source\"])\n",
    "    ds.expand_dims(dim)\n",
    "    assert m_id_re is not None\n",
    "    m_id: Union[str, int]\n",
    "    try:\n",
    "        m_id = int(m_id_re.group(1))\n",
    "    except:\n",
    "        m_id = str(m_id_re.group(1))\n",
    "    ds[dim] = m_id\n",
    "    return ds.drop_vars(drop_vars, errors=\"ignore\").drop_dims(drop_dims, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6fe9a-ea2a-4975-931e-3a14ac2c4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "jib = xr.open_dataset(\"/mnt/storstrommen/pism-greenland/data_sets/ocean/fldmean_jib_ocean_forcing_id_ctrl_1980_2020.nc\").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f70f95-fa1f-4826-9ccb-2d7398f815e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = Path(\"/mnt/storstrommen/pism-greenland/data_sets/ocean/\").glob(\"MAR3.9_*_ocean_1960-2100_v4.nc\")\n",
    "ps = [p for p in ps if \"ctrl_proj\" not in p.name]\n",
    "ds = xr.open_mfdataset(ps, \n",
    "                       parallel=True,\n",
    "                       chunks=\"auto\",\n",
    "                       preprocess=partial(preprocess_nc, regexp=\"MAR3.9_(.+?)_ocean\"),\n",
    "                       combine=\"nested\",\n",
    "                       concat_dim=\"exp_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4ac99-e0d6-4379-ad45-1a0b7c10ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = xr.open_dataset(\"/home/andy/Downloads/FinalOutput/generatedTF_allglaciersinshore_MIROCES2L_MembersAverage_hist2100ssp585.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4fa63-517b-4f2c-85ce-bbdcc4a58e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_year_to_datetime(decimal_year):\n",
    "    year = int(decimal_year)\n",
    "    rem = decimal_year - year\n",
    "\n",
    "    base = datetime(year, 1, 1)\n",
    "    result = base + timedelta(seconds=(base.replace(year=base.year + 1) - base).total_seconds() * rem)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d342b1-d284-4cbf-bbfd-fced03a3c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal_year = recon.time.to_numpy()\n",
    "datetimes = [decimal_year_to_datetime(year) for year in decimal_year]\n",
    "glacier = recon.Glacier.to_numpy()\n",
    "realization = recon.RealizationNumber.to_numpy()\n",
    "theta_ocean = recon.TF.to_numpy()\n",
    "lat = recon.lat.to_numpy()\n",
    "lon = recon.lon.to_numpy()\n",
    "\n",
    "r_ds = xr.Dataset(coords={\"time\": datetimes, \"glacier\": glacier, \"realization\": realization},\n",
    "                 data_vars={\"lat\": ([\"glacier\"], lat),\n",
    "                            \"lon\": ([\"glacier\"], lon),\n",
    "                            \"theta_ocean\": ([\"realization\", \"glacier\", \"time\"], theta_ocean, {\"units\": \"K\"})})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f160df2-23a6-49e7-9e85-41fd080aca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3413\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1ab38-226c-4162-9929-5df4ccd27e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = transformer.transform(r_ds.lat, r_ds.lon)\n",
    "X = xr.DataArray(x, coords={\"glacier\": glacier}, name=\"x\")\n",
    "Y = xr.DataArray(y, coords={\"glacier\": glacier}, name=\"y\")\n",
    "r_ds = xr.merge([r_ds, X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e5e65-e861-4626-9282-91e44a4e93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcms = ds.sel(time=slice(\"1980-01-01\", \"2010-01-01\"))\n",
    "reanalysis = r_ds.sel(time=slice(\"1980-01-01\", \"2010-01-01\")).rolling(time=13).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8ae35-a62e-4210-a80a-46bfaba03fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [86, 161]:\n",
    "    reanalysis_glacier = reanalysis.isel(glacier=k)\n",
    "    pos = {\"x\": reanalysis_glacier.x, \"y\": reanalysis_glacier.y}\n",
    "    gcm_theta = gcms.sel(pos, method=\"nearest\").theta_ocean\n",
    "    reanalysis_theta = reanalysis_glacier.theta_ocean\n",
    "    reanalysis_theta_mean = reanalysis_theta.mean(dim=\"realization\")\n",
    "    reanalysis_theta_std = reanalysis_theta.std(dim=\"realization\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.2, 3.2))\n",
    "    ax.fill_between(reanalysis_theta_mean.time, reanalysis_theta_mean - reanalysis_theta_std, reanalysis_theta_mean + reanalysis_theta_std, \n",
    "                    color=\"k\", alpha=0.20, lw=0)\n",
    "    reanalysis_theta_mean.plot.line(lw=2, ax=ax)\n",
    "    gcm_theta.plot.line(x=\"time\", hue=\"exp_id\", ax=ax, color=\"0.5\", lw=1, add_legend=False)        \n",
    "    glacier_name = reanalysis_theta.glacier.values\n",
    "    ax.set_title(glacier_name)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{glacier_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a21f4-5a40-4882-98f1-5435c6dc9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "    k = 86\n",
    "    reanalysis_glacier = reanalysis.isel(glacier=k)\n",
    "    pos = {\"x\": reanalysis_glacier.x, \"y\": reanalysis_glacier.y}\n",
    "    gcm_theta = gcms.sel(pos, method=\"nearest\").theta_ocean\n",
    "    reanalysis_theta = reanalysis_glacier.theta_ocean\n",
    "    reanalysis_theta_mean = reanalysis_theta.mean(dim=\"realization\")\n",
    "    reanalysis_theta_std = reanalysis_theta.std(dim=\"realization\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.2, 3.2))\n",
    "    ax.fill_between(reanalysis_theta_mean.time, reanalysis_theta_mean - reanalysis_theta_std, reanalysis_theta_mean + reanalysis_theta_std, \n",
    "                    color=\"k\", alpha=0.20, lw=0)\n",
    "    reanalysis_theta_mean.plot.line(lw=2, ax=ax)\n",
    "    gcm_theta.plot.line(x=\"time\", hue=\"exp_id\", color=\"0.5\", ax=ax, add_legend=False)        \n",
    "    jib.theta_ocean.plot.line(hue=\"exp_id\", ax=ax, lw=2)\n",
    "    glacier_name = reanalysis_theta.glacier.values\n",
    "    ax.set_title(glacier_name)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{glacier_name}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d2dcd-fb07-45c9-a6d1-f5cd10faf605",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = recon.time\n",
    "plt.figure()\n",
    "tf = recon.isel(glacierDim=86).TF.mean(dim=\"realizDim\").rolling(timeDim=13).mean()\n",
    "plt.plot(time, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24c89a-d775-4912-be88-f5f25004a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, g in enumerate(reanalysis.glacier):\n",
    "    print(k, g.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993160e3-d9fa-4f53-b816-c3f8a8f2116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tf, lw=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4714ca-9353-4635-9841-0ee00169398c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
