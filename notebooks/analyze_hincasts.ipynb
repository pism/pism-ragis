{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43204f3d",
   "metadata": {},
   "source": [
    "# Compare RAGIS ice-sheet wide timeseries to IMBIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de938c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pismragis.observations import load_imbie, load_imbie_csv\n",
    "from pismragis.analysis import resample_ensemble_by_data\n",
    "from pismragis.processing import convert_netcdf_to_dataframe, check_file, copy_file\n",
    "from pismragis.sensitivity import sensitivity_analysis\n",
    "from pismragis.stats import run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 8\n",
    "norm_year = 1992.0\n",
    "\n",
    "plt.rc('font', size=6)\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "\n",
    "mass_varname = f\"Contribution to sea-level since {int(norm_year)} (cm SLE)\"\n",
    "flux_varname = \"D (Gt/yr)\"\n",
    "bg_color = \"#216779\"\n",
    "bg_color = \"w\"\n",
    "\n",
    "sim_colors = plt.rcParams['axes.prop_cycle'].by_key()['color'][1::]\n",
    "imbie_color = plt.rcParams['axes.prop_cycle'].by_key()['color'][0]\n",
    "    \n",
    "kg2cmsle = 1 / 1e12 * 1.0 / 362.5 / 10.0\n",
    "gt2cmsle = 1 / 362.5 / 10.0\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67ae0ff",
   "metadata": {},
   "source": [
    "## Load IMBIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbie = load_imbie(url=\"../imbie_dataset_greenland_dynamics-2020_02_28.xlsx\")\n",
    "imbie = load_imbie_csv(url=\"../data/imbie_greenland_2021_Gt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c689537",
   "metadata": {},
   "source": [
    "glob PISM scalar time series files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5777a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../hindcasts\"\n",
    "\n",
    "experiments = []\n",
    "\n",
    "exp = {\n",
    "    \"Experiment\": \"salinity\",\n",
    "    \"proj_dir\": \"2023_04_ocean_calving_50\",\n",
    "    \"scalar_dir\": \"scalar\",\n",
    "    \"processed_dir\": \"processed\",\n",
    "    \"lhs\": \"gris_ragis_ocean_calving_lhs_50_w_posterior\",\n",
    "}\n",
    "\n",
    "ens_file = os.path.join(data_dir, exp[\"proj_dir\"], \"uq\", f\"\"\"{exp[\"lhs\"]}.csv\"\"\")\n",
    "s_dir = os.path.join(data_dir, exp[\"proj_dir\"], exp[\"scalar_dir\"])\n",
    "scalar_files = sorted(glob(os.path.join(s_dir, \"ts_gris_g*00m_v20*RAGIS_id_*_1980-1-1_2020-1-1.nc\")))\n",
    "processed_path = os.path.join(data_dir, exp[\"proj_dir\"], exp[\"processed_dir\"])\n",
    "\n",
    "\n",
    "for scalar_file in scalar_files:\n",
    "    if check_file(scalar_file):\n",
    "        copy_file(scalar_file, processed_path)\n",
    "        \n",
    "processed_files = sorted(glob(os.path.join(processed_path, \"ts_gris_g*00m_v20*RAGIS_id_*_1980-1-1_2020-1-1.nc\")))\n",
    "\n",
    "exp_df = convert_netcdf_to_dataframe(processed_files, resample=\"yearly\", verbose=False, n_jobs=n_jobs)\n",
    "exp_df[\"Experiment\"] = exp[\"Experiment\"]\n",
    "exp[\"data_df\"] = exp_df\n",
    "exp[\"run_stats\"] = run_stats(processed_files, experiment=exp[\"Experiment\"])\n",
    "sa_df = sensitivity_analysis(exp_df.dropna(), ensemble_file=ens_file, n_jobs=n_jobs)\n",
    "exp[\"sensitivity_df\"] = sa_df\n",
    "experiments.append(exp)\n",
    "\n",
    "exp = {\n",
    "    \"Experiment\": \"tct\",\n",
    "    \"proj_dir\": \"2023_04_thickness_calving_50\",\n",
    "    \"scalar_dir\": \"scalar\",\n",
    "    \"processed_dir\": \"processed\",\n",
    "    \"lhs\": \"gris_ragis_thickness_calving_lhs_50_w_posterior\",\n",
    "}\n",
    "\n",
    "ens_file = os.path.join(data_dir, exp[\"proj_dir\"], \"uq\", f\"\"\"{exp[\"lhs\"]}.csv\"\"\")\n",
    "s_dir = os.path.join(data_dir, exp[\"proj_dir\"], exp[\"scalar_dir\"])\n",
    "scalar_files = sorted(glob(os.path.join(s_dir, \"ts_gris_g*00m_v20*RAGIS_id_*_1980-1-1_2020-1-1.nc\")))\n",
    "processed_path = os.path.join(data_dir, exp[\"proj_dir\"], exp[\"processed_dir\"])\n",
    "\n",
    "\n",
    "for scalar_file in scalar_files:\n",
    "    if check_file(scalar_file):\n",
    "        copy_file(scalar_file, processed_path)\n",
    "        \n",
    "processed_files = sorted(glob(os.path.join(processed_path, \"ts_gris_g*00m_v20*RAGIS_id_*_1980-1-1_2020-1-1.nc\")))\n",
    "\n",
    "exp_df = convert_netcdf_to_dataframe(processed_files, resample=\"yearly\", verbose=False, n_jobs=n_jobs)\n",
    "exp_df[\"Experiment\"] = exp[\"Experiment\"]\n",
    "exp[\"data_df\"] = exp_df\n",
    "exp[\"run_stats\"] = run_stats(processed_files, experiment=exp[\"Experiment\"])\n",
    "sa_df = sensitivity_analysis(exp_df.dropna(), ensemble_file=ens_file, n_jobs=n_jobs)\n",
    "exp[\"sensitivity_df\"] = sa_df\n",
    "experiments.append(exp)\n",
    "\n",
    "# exp = {\n",
    "#     \"Experiment\": \"frontal melt\",\n",
    "#     \"proj_dir\": \"2023_04_ocean_50\",\n",
    "#     \"scalar_dir\": \"scalar\",\n",
    "#     \"processed_dir\": \"processed\",\n",
    "#     \"lhs\": \"gris_ragis_ocean_lhs_50_w_posterior\",\n",
    "# }\n",
    "\n",
    "# ens_file = os.path.join(data_dir, exp[\"proj_dir\"], \"uq\", f\"\"\"{exp[\"lhs\"]}.csv\"\"\")\n",
    "# s_dir = os.path.join(data_dir, exp[\"proj_dir\"], exp[\"scalar_dir\"])\n",
    "# scalar_files = sorted(glob(os.path.join(s_dir, \"ts_gris_g*00m_v20*RAGIS_id_*_1980-1-1_2020-1-1.nc\")))\n",
    "# processed_path = os.path.join(data_dir, exp[\"proj_dir\"], exp[\"processed_dir\"])\n",
    "\n",
    "\n",
    "# for scalar_file in scalar_files:\n",
    "#     if check_file(scalar_file):\n",
    "#         copy_file(scalar_file, processed_path)\n",
    "        \n",
    "# processed_files = sorted(glob(os.path.join(processed_path, \"ts_gris_g*00m_v20*RAGIS_id_*_1980-1-1_2020-1-1.nc\")))\n",
    "\n",
    "# exp_df = convert_netcdf_to_dataframe(processed_files, resample=\"yearly\", verbose=False, n_jobs=n_jobs)\n",
    "# exp_df[\"Experiment\"] = exp[\"Experiment\"]\n",
    "# exp[\"data_df\"] = exp_df\n",
    "# exp[\"run_stats\"] = run_stats(processed_files, experiment=exp[\"Experiment\"])\n",
    "# sa_df = sensitivity_analysis(exp_df.dropna(), ensemble_file=ens_file, n_jobs=n_jobs)\n",
    "# exp[\"sensitivity_df\"] = sa_df\n",
    "# experiments.append(exp)\n",
    "\n",
    "# exp = {\n",
    "#     \"Experiment\": \"ctrl\",\n",
    "#     \"proj_dir\": \"2023_04_ocean_simple_50\",\n",
    "#     \"scalar_dir\": \"scalar\",\n",
    "#     \"processed_dir\": \"processed\",\n",
    "#     \"lhs\": \"gris_ragis_ocean_simple_lhs_50_w_posterior\",\n",
    "# }\n",
    "\n",
    "# ens_file = os.path.join(data_dir, exp[\"proj_dir\"], \"uq\", f\"\"\"{exp[\"lhs\"]}.csv\"\"\")\n",
    "# s_dir = os.path.join(data_dir, exp[\"proj_dir\"], exp[\"scalar_dir\"])\n",
    "# scalar_files = sorted(glob(os.path.join(s_dir, \"ts_gris_g*00m_v20*RAGIS_id_*_1980-1-1_2020-1-1.nc\")))\n",
    "# processed_path = os.path.join(data_dir, exp[\"proj_dir\"], exp[\"processed_dir\"])\n",
    "\n",
    "\n",
    "# for scalar_file in scalar_files:\n",
    "#     if check_file(scalar_file):\n",
    "#         copy_file(scalar_file, processed_path)\n",
    "        \n",
    "# processed_files = sorted(glob(os.path.join(processed_path, \"ts_gris_g*00m_v20*RAGIS_id_*_1980-1-1_2020-1-1.nc\")))\n",
    "\n",
    "# exp_df = convert_netcdf_to_dataframe(processed_files, resample=\"yearly\", verbose=False, n_jobs=n_jobs)\n",
    "# exp_df[\"Experiment\"] = exp[\"Experiment\"]\n",
    "# exp[\"data_df\"] = exp_df\n",
    "# exp[\"run_stats\"] = run_stats(processed_files)\n",
    "# sa_df = sensitivity_analysis(exp_df.dropna(), ensemble_file=ens_file, n_jobs=n_jobs)\n",
    "# exp[\"sensitivity_df\"] = sa_df\n",
    "# experiments.append(exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=6)\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "\n",
    "e = experiments[0][\"run_stats\"]\n",
    "m_vars = [\"processor_hours\", \"wall_clock_hours\", \"model_years_per_processor_hour\"]\n",
    "for m in range(len(experiments)):\n",
    "    e_df = experiments[m][\"run_stats\"]\n",
    "    print(f\"\"\"Peformace Summary for Experiment {experiments[m][\"Experiment\"]} ({len(e_df)} members)\"\"\")\n",
    "    print(\"---------------------------------------------------\\n\")\n",
    "    print(e_df.agg({'processor_hours': 'sum', 'wall_clock_hours': \"sum\", \"model_years_per_processor_hour\": \"mean\"}))\n",
    "    print(\"---------------------------------------------------\\n\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(m_vars), sharey=\"row\", figsize=[6.2, 2.0])\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "\n",
    "all_run_stats = pd.concat([experiments[k][\"run_stats\"] for k in range(len(experiments))]).reset_index(drop=True)\n",
    "[sns.histplot(data=all_run_stats, x=m_var, bins=11, kde=True, hue=\"Experiment\", ax=axs[k]) for k, m_var in enumerate(m_vars)]\n",
    "axs[0].legend([], [], frameon=False)\n",
    "axs[1].legend([], [], frameon=False)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"run_stats.pdf\")\n",
    "!open run_stats.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e09670",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "Plot time series of cumulative mass change (cm SLE) and discharge at grounding line (Gt/yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=6)\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, sharex=\"col\", figsize=(6.2, 3.6))\n",
    "fig.subplots_adjust(wspace=0.0, hspace=0.0)\n",
    "\n",
    "axs[0].fill_between(imbie[\"Date\"], \n",
    "                    (imbie[\"Mass (Gt)\"] + sigma * imbie[\"Mass uncertainty (Gt)\"]) * gt2cmsle, \n",
    "                    (imbie[\"Mass (Gt)\"] - sigma * imbie[\"Mass uncertainty (Gt)\"]) / 362.5 / 10.0, \n",
    "                    ls=\"solid\", color=imbie_color, lw=0, alpha=0.5, label=\"observed (2-$\\sigma$)\")\n",
    "axs[1].fill_between(imbie[\"Date\"], \n",
    "                    (imbie[\"D (Gt/yr)\"] + sigma * imbie[\"D uncertainty (Gt/yr)\"]), \n",
    "                    (imbie[\"D (Gt/yr)\"] - sigma * imbie[\"D uncertainty (Gt/yr)\"]), \n",
    "                    ls=\"solid\", color=imbie_color, lw=0, alpha=0.5)\n",
    "\n",
    "# all_exps = pd.concat([experiments[e][\"data_df\"] for e in range(len(experiments))]).reset_index(drop=True)\n",
    "# sns.lineplot(data=all_exps, x=\"time\", y=mass_varname, hue=\"Experiment\", palette=sim_colors[:2], ax=axs[0], estimator=\"median\", ci=None)\n",
    "# sns.lineplot(data=all_exps, x=\"time\", y=flux_varname, hue=\"Experiment\", palette=sim_colors[:2], ax=axs[1], estimator=\"median\", ci=None)\n",
    "\n",
    "for k, exp in enumerate(experiments):\n",
    "    df = exp[\"data_df\"]\n",
    "    q_05 = df.groupby(by=\"time\").quantile(0.05, numeric_only=True)\n",
    "    q_50 = df.groupby(by=\"time\").quantile(0.50, numeric_only=True)\n",
    "    q_95 = df.groupby(by=\"time\").quantile(0.95, numeric_only=True)\n",
    "    axs[0].plot(q_50.index, q_50[mass_varname], color=sim_colors[k], alpha=1.0, lw=1)\n",
    "    axs[1].plot(q_50.index, q_50[flux_varname], color=sim_colors[k], alpha=1.0, lw=1)\n",
    "    axs[0].fill_between(q_05.index, q_05[mass_varname], \n",
    "                        q_95[mass_varname], color=sim_colors[k], alpha=0.4, lw=1, label=exp[\"Experiment\"])\n",
    "    axs[1].fill_between(q_05.index, q_05[flux_varname], \n",
    "                        q_95[flux_varname], color=sim_colors[k], alpha=0.4, lw=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.set_facecolor(bg_color)\n",
    "for ax in axs:\n",
    "    ax.set_facecolor(bg_color)\n",
    "fig.set_facecolor(bg_color)\n",
    "\n",
    "axs[0].axhline(0, color=\"k\", ls=\"dotted\", lw=1.0)\n",
    "axs[0].set_xlabel(\"\")\n",
    "axs[0].set_ylabel(\"Contribution to sea-level since 1992\\n(cm SLE)\")\n",
    "axs[1].set_xlabel(\"Year\")\n",
    "axs[1].set_ylabel(\"Solid Discharge (Gt/yr)\")\n",
    "axs[0].set_xlim(pd.to_datetime(\"1980-1-1\"), pd.to_datetime(\"2020-1-1\"))\n",
    "axs[0].set_ylim(-1.5, 1.0)\n",
    "axs[1].set_ylim(-1000, 100)\n",
    "legend = axs[0].legend(loc=\"lower left\")\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "legend.get_frame().set_alpha(0.0)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"ragis-comp_scalar.pdf\")\n",
    "!open ragis-comp_scalar.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66402b7f",
   "metadata": {},
   "source": [
    "## Plot sensitivity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ac98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=6)\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "\n",
    "\n",
    "for e in experiments:\n",
    "    sa_df = e[\"sensitivity_df\"]\n",
    "    si = \"S1\"\n",
    "    outfile = f\"\"\"{e[\"lhs\"]}.pdf\"\"\"\n",
    "    fig, axs = plt.subplots(\n",
    "        2,\n",
    "        1,\n",
    "        sharex=\"col\",\n",
    "        figsize=[6.2, 3.8],\n",
    "    )\n",
    "    fig.subplots_adjust(bottom=0.0)\n",
    "    for k, m_var in enumerate([\"limnsw (kg)\", \"grounding_line_flux (Gt year-1)\"]):\n",
    "        m_df = sa_df[sa_df[\"Variable\"] == m_var]\n",
    "        ax = axs.ravel()[k]\n",
    "        p_df = m_df[m_df[\"Si\"] == si].drop(columns=[\"Si\", \"Variable\"]).set_index(\"Date\")\n",
    "        p_conf_df = m_df[m_df[\"Si\"] == si + \"_conf\"].drop(columns=[\"Si\"])\n",
    "\n",
    "        [\n",
    "            ax.plot(p_df.index, p_df[v], lw=1, label=v)\n",
    "            for v in sa_df.drop(columns=[\"Si\", \"Variable\", \"Date\"]).keys()\n",
    "        ]\n",
    "\n",
    "        [\n",
    "            ax.fill_between(\n",
    "                p_df.index,\n",
    "                p_df[v].values - p_conf_df[v].values,\n",
    "                p_df[v].values + p_conf_df[v].values,\n",
    "                alpha=0.2,\n",
    "                lw=0,\n",
    "            )\n",
    "            for v in sa_df.drop(columns=[\"Si\", \"Variable\", \"Date\"]).keys()\n",
    "        ]\n",
    "        ax.set_xlim(datetime(1980, 1, 1), datetime(2020, 1, 1))\n",
    "        lgd = ax.set_title(f\"{si} indices for '{m_var}'\")\n",
    "    legend = axs[-1].legend(loc=\"lower left\", ncols=3, bbox_to_anchor=(0, -0.75))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{si}_{outfile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef451a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragis_calib = resample_ensemble_by_data(imbie, experiments[1][\"data_df\"], \n",
    "                                        fudge_factor=100)\n",
    "calib_exps = ragis_calib[\"Experiment\"].unique()\n",
    "print(calib_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d852e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=1, sharex=\"col\", figsize=(12, 8))\n",
    "fig.subplots_adjust(wspace=0.0, hspace=0.0)\n",
    "\n",
    "q_5 = ragis_calib.groupby(by=\"Year\").quantile(0.05)\n",
    "q_16 = ragis_calib.groupby(by=\"Year\").quantile(0.16)\n",
    "q_50 = ragis_calib.groupby(by=\"Year\").quantile(0.50)\n",
    "q_84 = ragis_calib.groupby(by=\"Year\").quantile(0.84)\n",
    "q_95 = ragis_calib.groupby(by=\"Year\").quantile(0.95)\n",
    "for exp in calib_exps:\n",
    "    e = data_df[data_df[\"Experiment\"] == exp]\n",
    "    axs[0].plot(e[\"Year\"], e[\"Mass (Gt)\"])\n",
    "    axs[1].plot(e[\"Year\"], e[\"D (Gt/yr)\"])\n",
    "\n",
    "# axs[0].fill_between(q_50.index, q_16[\"Mass (Gt)\"], q_84[\"Mass (Gt)\"], color=\"w\")\n",
    "axs[0].fill_between(imbie[\"Year\"], \n",
    "                    (imbie[\"Mass (Gt)\"] + sigma * imbie[\"Mass uncertainty (Gt)\"]), \n",
    "                    (imbie[\"Mass (Gt)\"] - sigma * imbie[\"Mass uncertainty (Gt)\"]), \n",
    "                    ls=\"solid\", lw=0, alpha=0.5, color=\"#6baed6\", label=\"2-$\\sigma$ IMBIE\")\n",
    "axs[1].fill_between(imbie[\"Year\"], \n",
    "                    (imbie[\"D (Gt/yr)\"] + sigma * imbie[\"D uncertainty (Gt/yr)\"]), \n",
    "                    (imbie[\"D (Gt/yr)\"] - sigma * imbie[\"D uncertainty (Gt/yr)\"]), \n",
    "                    ls=\"solid\", lw=0, alpha=1, color=imbie_color)\n",
    "\n",
    "\n",
    "axs[0].set_xlim(1992, 2017)\n",
    "fig.set_facecolor(bg_color)\n",
    "for ax in axs:\n",
    "    ax.set_facecolor(bg_color)\n",
    "fig.set_facecolor(bg_color)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0e9a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sensitivity_analysis in module pismragis.analysis:\n",
      "\n",
      "sensitivity_analysis(df: pandas.core.frame.DataFrame, ensemble_file: str, calc_variables: Union[str, list] = ['grounding_line_flux (Gt year-1)', 'limnsw (kg)'], n_jobs: int = 4, sensitivity_indices: Union[str, list] = ['delta', 'S1']) -> pandas.core.frame.DataFrame\n",
      "    Calculate sensitivity indices using SALIB and return pd.DataFrame\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    df : pd.DataFrame\n",
      "        A DataFrame procduced with processing.convert_netcdf_to_dataframe\n",
      "    ensemble_file: str\n",
      "        A csv file that maps ensemble member id's to parameters\n",
      "    calc_variables: list\n",
      "        A list of variables for which sensitivity indices are calculated\n",
      "    n_jobs: int\n",
      "        Number of parallel workers\n",
      "    sensitivity_indices: str or list\n",
      "        A list of sensitivity indices\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    pd.DataFrame\n",
      "        A Pandas DataFrame with sensitivity indices\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(analysis.sensitivity_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95dcd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pismragis import processing, analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90c0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing.ncfile2dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03df637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.prepare_df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d5336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
