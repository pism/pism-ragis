{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ee8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import contextlib\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Union\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "from pismragis.processing import convert_netcdf_to_dataframe, ncfile2dataframe\n",
    "from pismragis.analysis import prepare_df, sensitivity_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "infiles = glob(\"../tests/data/ts_gris_g1200m_v2023_RAGIS_id_*_1980-1-1_2020-1-1.nc\")\n",
    "df = convert_netcdf_to_dataframe(infiles, add_vars=False)\n",
    "df.to_parquet(\"../tests/data/test_scalar.parquet\")\n",
    "df.to_csv(\"../tests/data/test_scalar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a08881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_netcdf_to_dataframe(infiles, add_vars=False, resample=\"yearly\")\n",
    "df = df[df.time.between(\"1980-01-01\", \"1982-01-01\")].reset_index(drop=True)\n",
    "df.to_parquet(\"../tests/data/test_scalar_YM.parquet\")\n",
    "df.to_csv(\"../tests/data/test_scalar_YM.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"../tests/data/ts_gris_g1200m_v2023_RAGIS_id_0_1980-1-1_2020-1-1.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ncfile2dataframe(infile, add_vars=False)\n",
    "df.to_parquet(\"../tests/data/test_scalar_file.parquet\")\n",
    "df.to_csv(\"../tests/data/test_scalar_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92615439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ncfile2dataframe(infile, add_vars=True)\n",
    "df.to_parquet(\"../tests/data/test_scalar_file_add_vars.parquet\")\n",
    "df.to_csv(\"../tests/data/test_scalar_file_add_vars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730552fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_df = (\n",
    "        pd.read_parquet(\"../tests/data/test_scalar_YM.parquet\")\n",
    "        .drop(columns=[\"Year\", \"resolution_m\"])\n",
    "        .sort_values(by=[\"time\", \"id\"])\n",
    "    )\n",
    "    ensemble_file = \"../tests/data/gris_ragis_ocean_simple_lhs_50_w_posterior.csv\"\n",
    "    Y_df = sensitivity_analysis(\n",
    "        X_df, ensemble_file=ensemble_file, n_jobs=n_jobs, seed=seed\n",
    "    )\n",
    "    Y_df.to_parquet(\"../tests/data/test_sensitivity.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Y_true_df = pd.read_parquet(\"../tests/data/test_sensitivity.parquet\")\n",
    "    Y_df = sensitivity_analysis(\n",
    "        X_df, ensemble_file=ensemble_file, n_jobs=n_jobs, seed=seed\n",
    "    )\n",
    "    assert_frame_equal(Y_df, Y_true_df, rtol=1e-04)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ds = xr.open_mfdataset(\n",
    "        \"../tests/data/ts_gris_g1200m_v2023_RAGIS_id_*.nc\",\n",
    "        combine=\"nested\",\n",
    "        concat_dim=\"id\",\n",
    "        preprocess=nc_add_id,\n",
    "        parallel=True,\n",
    "    )\n",
    "    ens = (\n",
    "        ds.sel(time=slice(\"1980-01-01\", \"1982-01-01\"))[ens_vars_dict.keys()]\n",
    "        .resample(time=\"1AS\")\n",
    "        .mean()\n",
    "    )\n",
    "    X_xr_df = (\n",
    "        ens.to_dataframe()\n",
    "        .rename(columns=ens_vars_dict)\n",
    "        .reset_index()\n",
    "        .dropna()\n",
    "        .sort_values(by=[\"time\", \"id\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    Y_xr_df = sensitivity_analysis(\n",
    "        X_xr_df, ensemble_file=ensemble_file, n_jobs=n_jobs, seed=seed\n",
    "    )\n",
    "    assert_frame_equal(Y_xr_df, Y_true_df, atol=1e-01, rtol=1e-06)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "    infile = \"../tests/data/ts_gris_g1200m_v2023_RAGIS_id_0_1980-1-1_2020-1-1.nc\"\n",
    "\n",
    "    df_parquet_true = pd.read_parquet(\"../tests/data/test_scalar_file.parquet\")\n",
    "    df_csv_true = pd.read_csv(\n",
    "        \"../tests/data/test_scalar_file.csv\",\n",
    "        index_col=0,\n",
    "        infer_datetime_format=True,\n",
    "        parse_dates=[\"time\"],\n",
    "    )\n",
    "\n",
    "    df = ncfile2dataframe(infile, add_vars=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee01e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    assert_frame_equal(df, df_parquet_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true.to_parquet(\"tests/data/test_sensitivity.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(\"tests/data/ts_gris_g1200m_v2023_RAGIS_id_*.nc\", combine=\"nested\", concat_dim=\"id\", parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_vars = [\"grounding_line_flux\", \"limnsw\"]\n",
    "ens = ds.sel(time=slice(\"1980-01-01\" ,\"1983-01-01\"))[ens_vars].resample(time=\"1AS\").mean()\n",
    "ens_df = ens.to_dataframe().reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs=4\n",
    "\n",
    "Y_true_xr = sensitivity_analysis(ens_df, ensemble_file=ensemble_file, n_jobs=n_jobs, calc_variables=ens_vars)[sens_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01616486",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_parquet_true = pd.read_parquet(\"../tests/data/test_scalar_file_YM.parquet\")\n",
    "    df_csv_true = pd.read_csv(\n",
    "        \"../tests/data/test_scalar_file_YM.csv\",\n",
    "        index_col=0,\n",
    "        infer_datetime_format=True,\n",
    "        parse_dates=[\"time\"],\n",
    "    )\n",
    "\n",
    "    df = ncfile2dataframe(infile, resample=\"yearly\", add_vars=False)\n",
    "    assert_frame_equal(df, df_parquet_true)\n",
    "    assert_frame_equal(df, df_csv_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07caf062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncfile2dataframe(\n",
    "    infile: Union[str, pathlib.Path],\n",
    "    resample: Union[str, None] = None,\n",
    "    add_vars: bool = True,\n",
    "    norm_year: Union[None, float] = None,\n",
    "    verbose: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Convert netCDF file to pandas.DataFrame\"\"\"\n",
    "\n",
    "    if isinstance(infile, pathlib.Path):\n",
    "        assert infile.exists()\n",
    "    else:\n",
    "        assert os.path.isfile(infile)\n",
    "    if verbose:\n",
    "        print(f\"Opening {infile}\")\n",
    "    with xr.open_dataset(infile) as ds:\n",
    "        if resample == \"monthly\":\n",
    "            ds = ds.resample(time=\"1MS\").mean()\n",
    "        elif resample == \"yearly\":\n",
    "            ds = ds.resample(time=\"1YS\").mean()\n",
    "        else:\n",
    "            pass\n",
    "        if isinstance(infile, pathlib.Path):\n",
    "            m_id_re = re.search(\"id_(.+?)_\", str(infile))\n",
    "        else:\n",
    "            m_id_re = re.search(\"id_(.+?)_\", infile)\n",
    "        assert m_id_re is not None\n",
    "        m_id: Union[str, int]\n",
    "        try:\n",
    "            m_id = int(m_id_re.group(1))\n",
    "        except:\n",
    "            m_id = str(m_id_re.group(1))\n",
    "\n",
    "        if isinstance(infile, pathlib.Path):\n",
    "            m_dx_re = re.search(\"gris_g(.+?)m\", str(infile))\n",
    "        else:\n",
    "            m_dx_re = re.search(\"gris_g(.+?)m\", infile)\n",
    "        assert m_dx_re is not None\n",
    "        m_dx = int(m_dx_re.group(1))\n",
    "        datetimeindex = ds.indexes[\"time\"]\n",
    "        years = [to_decimal_year(x.to_pydatetime()) for x in datetimeindex]\n",
    "        nt = len(datetimeindex)\n",
    "        id_S = pd.Series(data=np.repeat(m_id, nt), index=datetimeindex, name=\"id\")\n",
    "        S = [id_S]\n",
    "        for m_var in ds.data_vars:\n",
    "            if m_var not in (\n",
    "                \"time_bounds\",\n",
    "                \"time_bnds\",\n",
    "                \"timestamp\",\n",
    "                \"run_stats\",\n",
    "                \"pism_config\",\n",
    "            ):\n",
    "                if hasattr(ds[m_var], \"units\"):\n",
    "                    m_units = ds[m_var].units\n",
    "                    m_S_name = f\"{m_var} ({m_units})\"\n",
    "                else:\n",
    "                    m_units = \"\"\n",
    "                    m_S_name = f\"{m_var}\"\n",
    "                data = np.squeeze(ds[m_var].values)\n",
    "                m_S = pd.Series(data=data, index=datetimeindex, name=m_S_name)\n",
    "                S.append(m_S)\n",
    "        m_Y = pd.Series(data=years, index=datetimeindex, name=\"Year\")\n",
    "        S.append(m_Y)\n",
    "        df = pd.concat(S, axis=1).reset_index()\n",
    "        df[\"resolution_m\"] = m_dx\n",
    "        \n",
    "        if add_vars:\n",
    "            df = add_vars_to_dataframe(df)\n",
    "        \n",
    "        if norm_year:\n",
    "            norm_year_idx = np.nonzero(np.array(years) == norm_year)[0][0]\n",
    "            df[\"limnsw (kg)\"] -= df[\"limnsw (kg)\"][norm_year_idx]\n",
    "            if add_vars:\n",
    "                df[\"Cumulative ice sheet mass change (Gt)\"] += df[\n",
    "                    \"Cumulative ice sheet mass change (Gt)\"\n",
    "                ][norm_year_idx]\n",
    "                df[\"SLE (cm)\"] += df[\"SLE (cm)\"][norm_year_idx]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_vars_to_dataframe(df: pd.DataFrame):\n",
    "    \"\"\"Add additional variables to DataFrame\"\"\"\n",
    "\n",
    "    if \"limnsw (kg)\" in df.columns:\n",
    "        df[\"Cumulative ice sheet mass change (Gt)\"] = (\n",
    "            df[\"limnsw (kg)\"] - df[\"limnsw (kg)\"][0]\n",
    "        ) / 1e12\n",
    "        df[\"SLE (cm)\"] = df[\"Cumulative ice sheet mass change (Gt)\"] * gt2cmsle\n",
    "        if \"grounding_line_flux (Gt year-1)\" in df.columns:\n",
    "            df[\"Rate of ice discharge (Gt/yr)\"] = -df[\"grounding_line_flux (Gt year-1)\"]\n",
    "        if \"tendency_of_ice_mass_due_to_surface_mass_flux (Gt year-1)\" in df.columns:\n",
    "            df[\"Rate of surface mass balance (Gt/yr)\"] = df[\n",
    "                \"tendency_of_ice_mass_due_to_surface_mass_flux (Gt year-1)\"\n",
    "            ]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_parquet_true = pd.read_parquet(\"../tests/data/test_scalar_file.parquet\")\n",
    "    df_csv_true = pd.read_csv(\n",
    "        \"../tests/data/test_scalar_file.csv\",\n",
    "        index_col=0,\n",
    "        infer_datetime_format=True,\n",
    "        parse_dates=[\"time\"],\n",
    "    )\n",
    "\n",
    "    df = ncfile2dataframe(infile, add_vars=False)\n",
    "    assert_frame_equal(df, df_parquet_true)\n",
    "    assert_frame_equal(df, df_csv_true)\n",
    "\n",
    "    df_parquet_true = pd.read_parquet(\"../tests/data/test_scalar_file_YM.parquet\")\n",
    "    df_csv_true = pd.read_csv(\n",
    "        \"../tests/data/test_scalar_file_YM.csv\",\n",
    "        index_col=0,\n",
    "        infer_datetime_format=True,\n",
    "        parse_dates=[\"time\"],\n",
    "    )\n",
    "\n",
    "    df = ncfile2dataframe(infile, resample=\"yearly\", add_vars=False)\n",
    "    assert_frame_equal(df, df_parquet_true)\n",
    "    assert_frame_equal(df, df_csv_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_parquet_true = pd.read_parquet(\"../tests/data/test_scalar_file_add_vars.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = ncfile2dataframe(infile, add_vars=True, norm_year=1992.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccee91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_netcdf_to_dataframe(\n",
    "    infiles: list,\n",
    "    resample: Union[str, None] = None,\n",
    "    n_jobs: int = 4,\n",
    "    add_vars: bool = True,\n",
    "    norm_year: Union[None, float] = None,\n",
    "    verbose: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert list of netCDF files to Pandas DataFrame.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    n_files = len(infiles)\n",
    "    print(\"Converting netcdf files to pandas.DataFrame\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    start_time = time.perf_counter()\n",
    "    with tqdm_joblib(tqdm(desc=\"Processing files\", total=n_files)) as progress_bar:\n",
    "        result = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(ncfile2dataframe)(infile, resample, add_vars, norm_year, verbose)\n",
    "            for infile in infiles\n",
    "        )\n",
    "        del progress_bar\n",
    "    finish_time = time.perf_counter()\n",
    "    time_elapsed = finish_time - start_time\n",
    "    print(f\"Conversion finished in {time_elapsed:.0f} seconds\")\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "    df = pd.concat(result)\n",
    "\n",
    "    return df.sort_values(by=[\"time\", \"id\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c009daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_parquet_true = pd.read_parquet(\"../tests/data/test_scalar_add_vars.parquet\")\n",
    "    infiles = glob(\"../tests/data/ts_gris_g1200m_v2023_RAGIS_id_*_1980-1-1_2020-1-1.nc\")\n",
    "\n",
    "    df = convert_netcdf_to_dataframe(infiles, add_vars=True, norm_year=1992.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        \"\"\"TQDM Callback\"\"\"\n",
    "\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    infiles = glob(\"../tests/data/ts_gris_g1200m_v2023_RAGIS_id_*_1980-1-1_1982-1-1.nc\")\n",
    "    df = convert_netcdf_to_dataframe(infiles, resample=\"yearly\", add_vars=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24f983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
